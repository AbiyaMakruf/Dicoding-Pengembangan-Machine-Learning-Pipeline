{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " Temperature             0\n",
      "Humidity                0\n",
      "Wind Speed              0\n",
      "Precipitation (%)       0\n",
      "Cloud Cover             0\n",
      "Atmospheric Pressure    0\n",
      "UV Index                0\n",
      "Season                  0\n",
      "Visibility (km)         0\n",
      "Location                0\n",
      "Weather Type            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./data/data.csv')\n",
    "data\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "# Drop rows with missing values (if any)\n",
    "data = data.dropna()\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['Cloud Cover', 'Season', 'Location', 'Weather Type']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Normalize numerical features\n",
    "numerical_columns = ['Temperature', 'Humidity', 'Wind Speed', 'Precipitation (%)', \n",
    "                     'Atmospheric Pressure', 'UV Index', 'Visibility (km)']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('Weather Type', axis=1)\n",
    "y = data['Weather Type']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cloud Cover': LabelEncoder(),\n",
       " 'Season': LabelEncoder(),\n",
       " 'Location': LabelEncoder(),\n",
       " 'Weather Type': LabelEncoder()}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 1ms/step - loss: 0.2405 - accuracy: 0.9068\n",
      "83/83 [==============================] - 0s 1ms/step\n",
      "Test Accuracy: 90.68%\n",
      "Predicted classes for the first 10 test samples: [3 3 3 2 3 2 3 1 2 2]\n",
      "True classes for the first 10 test samples: [3 3 3 2 3 2 3 1 3 2]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(len(np.unique(y)), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "test_accuracy = accuracy * 100\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Display the first few predictions\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(\"Predicted classes for the first 10 test samples:\", predicted_classes[:10])\n",
    "print(\"True classes for the first 10 test samples:\", y_test[:10].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4111     3\n",
       "10607    3\n",
       "7372     3\n",
       "11786    2\n",
       "12227    3\n",
       "        ..\n",
       "2543     1\n",
       "96       1\n",
       "2474     2\n",
       "2522     2\n",
       "3393     0\n",
       "Name: Weather Type, Length: 2640, dtype: int32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kolom numerik yang akan diperiksa outliers nya\n",
    "numeric_columns = ['Temperature', 'Humidity', 'Wind Speed','Precipitation (%)','Atmospheric Pressure','UV Index','Visibility (km)']\n",
    "\n",
    "# Menampilkan boxplot untuk masing-masing kolom\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, column in enumerate(numeric_columns, 1):\n",
    "    plt.subplot(2, 4, i)\n",
    "    sns.boxplot(y=data[column])\n",
    "    plt.title(f'Boxplot of {column}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Fungsi untuk menghapus outlier\n",
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "#Menghapus outliers dari masing-masing kolom\n",
    "for column in numeric_columns:\n",
    "    data = remove_outliers_iqr(data, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data asli:\n",
      " [[10. 20. 30.]\n",
      " [15. 25. 35.]\n",
      " [20. 30. 40.]]\n",
      "Data yang telah dinormalisasi:\n",
      " [[-1.2247449 -1.2247449 -1.2247449]\n",
      " [ 0.         0.         0.       ]\n",
      " [ 1.2247449  1.2247449  1.2247449]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Contoh data numerik\n",
    "data = np.array([[10.0, 20.0, 30.0],\n",
    "                 [15.0, 25.0, 35.0],\n",
    "                 [20.0, 30.0, 40.0]])\n",
    "\n",
    "# Buat layer normalisasi\n",
    "normalizer = tf.keras.layers.Normalization()\n",
    "\n",
    "# Adapt layer normalisasi pada data\n",
    "normalizer.adapt(data)\n",
    "\n",
    "# Terapkan normalisasi pada data\n",
    "normalized_data = normalizer(data)\n",
    "\n",
    "# Cetak hasil normalisasi\n",
    "print(\"Data asli:\\n\", data)\n",
    "print(\"Data yang telah dinormalisasi:\\n\", normalized_data.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-tfx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
